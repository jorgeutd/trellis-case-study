{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d21c478",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Install libraries ##################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa2a3668",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers safetensors sagemaker boto3  huggingface_hub --upgrade  --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a03ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Import libraries ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05328420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::730335220874:role/service-role/AmazonSageMaker-ExecutionRole-20240131T123268\n",
      "sagemaker bucket: sagemaker-us-east-1-730335220874\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cd4ccbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path at terminal when executing this file\n",
      "/home/ec2-user/SageMaker/Trellis\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"Path at terminal when executing this file\")\n",
    "print(os.getcwd() + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f099f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Model packaging and config ####### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "27c12839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00_data_preprocessing_trellis.ipynb\r\n",
      "01_training_model_v1_trellis.ipynb\r\n",
      "02_model_deployment_sagemaker_endpoint_Trellis_Doc.ipynb\r\n",
      "distilbert-base-uncased-finetuned-Trellis\r\n",
      "training-data\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4d01b3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir deployment_package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5369c0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/Trellis/deployment_package\n"
     ]
    }
   ],
   "source": [
    "cd deployment_package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b62fb6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1f57b0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ../distilbert-base-uncased-finetuned-Trellis/{config.json,pytorch_model.bin,special_tokens_map.json,tokenizer_config.json,vocab.txt} .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0183434a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing code/inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/inference.py\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import json\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"\n",
    "    Load the model and tokenizer from the specified directory.\n",
    "\n",
    "    Args:\n",
    "        model_dir (str): Directory where the model and tokenizer are stored.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the model, tokenizer, and device.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "        model.to(device)\n",
    "        return model, tokenizer, device\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading model or tokenizer: {e}\")\n",
    "        raise\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    \"\"\"\n",
    "    Process the input data.\n",
    "\n",
    "    Args:\n",
    "        request_body (str): The request body.\n",
    "        request_content_type (str): The content type of the request.\n",
    "\n",
    "    Returns:\n",
    "        dict: The processed input data.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the content type is unsupported.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if request_content_type == 'application/json':\n",
    "            data = json.loads(request_body)\n",
    "            return data\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported content type: {request_content_type}\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        logging.error(f\"Error decoding JSON: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing input data: {e}\")\n",
    "        raise\n",
    "\n",
    "def predict_fn(input_data, model_tokenizer_device):\n",
    "    \"\"\"\n",
    "    Generate predictions from the input data.\n",
    "\n",
    "    Args:\n",
    "        input_data (dict): The input data.\n",
    "        model_tokenizer_device (tuple): A tuple containing the model, tokenizer, and device.\n",
    "\n",
    "    Returns:\n",
    "        str: The predicted class label.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model, tokenizer, device = model_tokenizer_device\n",
    "        text = input_data['text']\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            predicted_class_id = logits.argmax().item()\n",
    "            predicted_class = model.config.id2label[predicted_class_id]\n",
    "        return predicted_class\n",
    "    except KeyError as e:\n",
    "        logging.error(f\"Key error: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error generating prediction: {e}\")\n",
    "        raise\n",
    "\n",
    "def output_fn(prediction, accept):\n",
    "    \"\"\"\n",
    "    Format the prediction output.\n",
    "\n",
    "    Args:\n",
    "        prediction (str): The predicted class label.\n",
    "        accept (str): The content type of the response.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the response body and content type.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the accept type is unsupported.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if accept == \"application/json\":\n",
    "            return json.dumps({\"predicted_class\": prediction}), accept\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported accept type: {accept}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error formatting output: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5f7f2773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing code/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/requirements.txt\n",
    "\n",
    "transformers\n",
    "torch\n",
    "safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "81121ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/Trellis\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2a902292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of 'deployment_package/':\n",
      "/\n",
      "    tokenizer_config.json\n",
      "    config.json\n",
      "    pytorch_model.bin\n",
      "    special_tokens_map.json\n",
      "    vocab.txt\n",
      "code/\n",
      "    requirements.txt\n",
      "    inference.py\n"
     ]
    }
   ],
   "source": [
    "def list_directory_contents(directory: str):\n",
    "    \"\"\"\n",
    "    List the contents of a directory.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Path to the directory.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(directory):\n",
    "        raise FileNotFoundError(f\"Directory '{directory}' not found.\")\n",
    "    \n",
    "    print(f\"Contents of '{directory}':\")\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        level = root.replace(directory, '').count(os.sep)\n",
    "        indent = ' ' * 4 * (level)\n",
    "        print(f\"{indent}{os.path.basename(root)}/\")\n",
    "        subindent = ' ' * 4 * (level + 1)\n",
    "        for f in files:\n",
    "            print(f\"{subindent}{f}\")\n",
    "\n",
    "# Define the path to the deployment package directory\n",
    "deployment_package_dir = 'deployment_package/'\n",
    "\n",
    "# List the contents of the deployment package directory\n",
    "try:\n",
    "    list_directory_contents(deployment_package_dir)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4273e22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ipynb_checkpoints(directory: str):\n",
    "    \"\"\"\n",
    "    Remove .ipynb_checkpoints directory from the specified directory.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Path to the directory.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for dir_name in dirs:\n",
    "            if dir_name == '.ipynb_checkpoints':\n",
    "                dir_path = os.path.join(root, dir_name)\n",
    "                shutil.rmtree(dir_path)\n",
    "                print(f\"Removed directory: {dir_path}\")\n",
    "\n",
    "# Remove .ipynb_checkpoints from the deployment package directory\n",
    "try:\n",
    "    remove_ipynb_checkpoints(deployment_package_dir)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2b0a83c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/Trellis\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4ede4088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deployment_package/'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment_package_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c5a022c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarball 'model.tar.gz' created successfully.\n",
      "Contents of the tarball:\n",
      "code\n",
      "code/inference.py\n",
      "code/requirements.txt\n",
      "tokenizer_config.json\n",
      "config.json\n",
      "pytorch_model.bin\n",
      "special_tokens_map.json\n",
      "vocab.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "\n",
    "def create_tarball(source_dir: str, output_filename: str):\n",
    "    \"\"\"\n",
    "    Create a tarball from the source directory.\n",
    "    \n",
    "    Args:\n",
    "        source_dir (str): Path to the source directory.\n",
    "        output_filename (str): Name of the output tarball file.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(source_dir):\n",
    "        raise FileNotFoundError(f\"Source directory '{source_dir}' not found.\")\n",
    "    \n",
    "    with tarfile.open(output_filename, \"w:gz\") as tar:\n",
    "        for item in os.listdir(source_dir):\n",
    "            item_path = os.path.join(source_dir, item)\n",
    "            tar.add(item_path, arcname=item)\n",
    "    \n",
    "    print(f\"Tarball '{output_filename}' created successfully.\")\n",
    "\n",
    "# Define the deployment package directory\n",
    "deployment_package_dir = 'deployment_package'\n",
    "\n",
    "# Define the output tarball filename\n",
    "output_tarball = 'model.tar.gz'\n",
    "\n",
    "# Create the tarball\n",
    "try:\n",
    "    create_tarball(deployment_package_dir, output_tarball)\n",
    "    \n",
    "    # Print the contents of the tarball\n",
    "    print(\"Contents of the tarball:\")\n",
    "    with tarfile.open(output_tarball, \"r:gz\") as tar:\n",
    "        for member in tar.getmembers():\n",
    "            print(member.name)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69da994c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Upload the trellis model.tar.gz file to an S3 bucket for model deployment #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b0376dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'model.tar.gz' uploaded to 's3://sagemaker-us-east-1-730335220874/distilbert-base-uncased-finetuned-trellis/model/model.tar.gz' successfully.\n"
     ]
    }
   ],
   "source": [
    "def upload_to_s3(file_path: str, bucket_name: str, s3_key: str):\n",
    "    \"\"\"\n",
    "    Upload a file to an S3 bucket.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the file to upload.\n",
    "        bucket_name (str): Name of the S3 bucket.\n",
    "        s3_key (str): S3 key for the uploaded file.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    s3 = boto3.client('s3')\n",
    "    try:\n",
    "        s3.upload_file(file_path, bucket_name, s3_key)\n",
    "        print(f\"File '{file_path}' uploaded to 's3://{bucket_name}/{s3_key}' successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading file to S3: {e}\")\n",
    "\n",
    "# Define the S3 bucket name and key\n",
    "bucket_name = 'sagemaker-us-east-1-730335220874'\n",
    "s3_key = 'distilbert-base-uncased-finetuned-trellis/model/model.tar.gz'\n",
    "\n",
    "# Upload the tarball to S3\n",
    "try:\n",
    "    upload_to_s3(output_tarball, bucket_name, s3_key)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3dff94",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Deploy the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "25578370",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: distilbert-hf-emails-trellis-document-class\n",
      "INFO:sagemaker:Creating endpoint-config with name distilbert-hf-emails-trellis-document-class\n",
      "INFO:sagemaker:Creating endpoint with name distilbert-hf-emails-trellis-document-class\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "def deploy_huggingface_model(s3_model_path: str, role: str, instance_type: str = 'ml.g4dn.2xlarge', \n",
    "                             instance_count: int = 1) -> sagemaker.predictor.Predictor:\n",
    "    \"\"\"\n",
    "    Deploy the Hugging Face model to SageMaker.\n",
    "\n",
    "    Args:\n",
    "        s3_model_path (str): S3 URI to the model tar.gz file.\n",
    "        role (str): Execution role for SageMaker.\n",
    "        instance_type (str, optional): Type of instance to deploy the model. Defaults to 'ml.g4dn.2xlarge'.\n",
    "        instance_count (int, optional): Number of instances for the deployment. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        sagemaker.predictor.Predictor: The deployed model predictor.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the specified instance type is not supported or if the instance count is less than 1.\n",
    "    \"\"\"\n",
    "    # Validate instance type and count\n",
    "    if instance_type not in ['ml.g4dn.2xlarge', 'ml.g4dn.4xlarge', 'ml.g4dn.8xlarge']:\n",
    "        raise ValueError(f\"Unsupported instance type: {instance_type}. Supported types: 'ml.g4dn.2xlarge','ml.g4dn.4xlarge', 'ml.g4dn.8xlarge'\")\n",
    "    if instance_count < 1:\n",
    "        raise ValueError(f\"Invalid instance count: {instance_count}. Instance count must be at least 1.\")\n",
    "\n",
    "    # Create a SageMaker Hugging Face Model\n",
    "    huggingface_model = HuggingFaceModel(\n",
    "        model_data=s3_model_path,\n",
    "        name='distilbert-hf-emails-trellis-document-class',\n",
    "        role=role,\n",
    "        transformers_version=\"4.26\",\n",
    "        pytorch_version=\"1.13\",\n",
    "        py_version='py39'\n",
    "    )\n",
    "\n",
    "    # Deploy the model\n",
    "    predictor = huggingface_model.deploy(\n",
    "        endpoint_name='distilbert-hf-emails-trellis-document-class',\n",
    "        endpoint_config_name='distilbert-hf-emails-trellis-document-class',\n",
    "        initial_instance_count=instance_count,\n",
    "        instance_type=instance_type,\n",
    "    )\n",
    "\n",
    "    return predictor\n",
    "\n",
    "\n",
    "# Define the S3 path to our Trellis Doc Class model\n",
    "s3_model_path = 's3://sagemaker-us-east-1-730335220874/distilbert-base-uncased-finetuned-trellis/model/model.tar.gz'\n",
    "\n",
    "# Get the SageMaker execution role\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# Deploy the model\n",
    "predictor = deploy_huggingface_model(s3_model_path, role, instance_type='ml.g4dn.2xlarge', instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66b6e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Test inference  'distilbert-hf-emails-trellis-document-class' endpoint ##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "230ce9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ent = \"\"\"Sundance to honour foreign films\n",
    "\n",
    "International films will be given the same prominence as US films at next year's Sundance Film Festival, with movies dominated by the theme of war.\n",
    "\n",
    "The independent film festival will feature two new international cinema competitions, during its 20-30 January season in Utah. Forty-two films will debut at Sundance, including The Liberace of Baghdad by British director Sean McAllister. The prestigious festival was founded by actor Robert Redford in 1981.\n",
    "\n",
    "\"We have always had an international component, but from next year they will enter a jury competition,\" festival director Geoffrey Gilmore said. \"We wanted to give world cinema more emphasis and have now put it on par with the American dramatic and documentary competitions.\" Twelve films competing in the new world cinema documentary category focus on countries and people under siege.\n",
    "\n",
    "The Liberace of Baghdad features an Iraqi pianist hiding in a hotel as he waits for a visa, while Finnish film The Three Rooms of Melancholia looks at the war in Chechnya. Shake Hands With The Devil: The Journey of Romeo Dallaire tells of a UN mission to Rwanda during the 1994 genocide, while French-Israeli production Wall looks at Israel's controversial security wall separating it from the Palestinian territories. The 16 films competing in the new world cinema dramatic category include works from Germany, South Korea, Angola, China, Denmark and Australia.\n",
    "\n",
    "Several Hollywood stars feature in the festival's American independent drama category, including Keanu Reeves and Benjamin Bratt. Vince Vaughn stars in quirky movie Thumbsucker while 21 Grams actress Naomi Watts plays a budding Hollywood actress in Ellie Parker. The top Grand Jury prize at this year's festival went to low budget sci-fi thriller Primer, written and directed by Shane Carruth. Morgan Spurlock earned the directing award for Super Size Me, which became an international box office hit.\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "77238c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Preprocessing the input text.\n",
      "INFO:__main__:Payload prepared: {\"text\": \"Sundance to honour foreign films International films will be given the same prominence as US films at next year's Sundance Film Festival, with movies dominated by the theme of war. The independent film festival will feature two new international cinema competitions, during its 20-30 January season in Utah. Forty-two films will debut at Sundance, including The Liberace of Baghdad by British director Sean McAllister. The prestigious festival was founded by actor Robert Redford in 1981. \\\"We have always had an international component, but from next year they will enter a jury competition,\\\" festival director Geoffrey Gilmore said. \\\"We wanted to give world cinema more emphasis and have now put it on par with the American dramatic and documentary competitions.\\\" Twelve films competing in the new world cinema documentary category focus on countries and people under siege. The Liberace of Baghdad features an Iraqi pianist hiding in a hotel as he waits for a visa, while Finnish film The Three Rooms of Melancholia looks at the war in Chechnya. Shake Hands With The Devil: The Journey of Romeo Dallaire tells of a UN mission to Rwanda during the 1994 genocide, while French-Israeli production Wall looks at Israel's controversial security wall separating it from the Palestinian territories. The 16 films competing in the new world cinema dramatic category include works from Germany, South Korea, Angola, China, Denmark and Australia. Several Hollywood stars feature in the festival's American independent drama category, including Keanu Reeves and Benjamin Bratt. Vince Vaughn stars in quirky movie Thumbsucker while 21 Grams actress Naomi Watts plays a budding Hollywood actress in Ellie Parker. The top Grand Jury prize at this year's festival went to low budget sci-fi thriller Primer, written and directed by Shane Carruth. Morgan Spurlock earned the directing award for Super Size Me, which became an international box office hit.\"}\n",
      "INFO:__main__:Invoking the SageMaker endpoint: distilbert-hf-emails-trellis-document-class\n",
      "INFO:__main__:Raw response from SageMaker endpoint: [\n",
      "  \"{\\\"predicted_class\\\": \\\"entertainment\\\"}\",\n",
      "  \"application/json\"\n",
      "]\n",
      "INFO:__main__:Parsed response from SageMaker endpoint: ['{\"predicted_class\": \"entertainment\"}', 'application/json']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from SageMaker endpoint: ['{\"predicted_class\": \"entertainment\"}', 'application/json']\n",
      "Predicted class: entertainment\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from html import unescape\n",
    "import logging\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def clean_text_content_trellis(text_content: str) -> str:\n",
    "    \"\"\"\n",
    "    Cleans text content of document text by performing several operations:\n",
    "    - Normalizes line breaks to Unix-style.\n",
    "    - Removes excessive whitespace within lines.\n",
    "    - Strips HTML tags and decodes HTML entities.\n",
    "    - Normalizes paragraph breaks to ensure readability.\n",
    "\n",
    "    Args:\n",
    "        text_content (str): The raw text content to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned text content.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Normalize line breaks to Unix-style\n",
    "        text_content = re.sub(r'\\r\\n|\\r', '\\n', text_content)\n",
    "        # Remove excessive whitespace within lines\n",
    "        text_content = re.sub(r'\\s+', ' ', text_content).strip()\n",
    "        # Strip HTML tags and decode HTML entities\n",
    "        text_content = re.sub(r'<[^>]+>', '', text_content, flags=re.DOTALL)\n",
    "        text_content = unescape(text_content)\n",
    "        # Normalize paragraph breaks to ensure readability\n",
    "        text_content = re.sub(r'\\n{3,}', '\\n\\n', text_content)\n",
    "        return text_content\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred while cleaning the text content: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def invoke_sagemaker_endpoint(endpoint_name: str, text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Preprocess the input text and invoke the SageMaker endpoint.\n",
    "\n",
    "    Args:\n",
    "        endpoint_name (str): The name of the SageMaker endpoint.\n",
    "        text (str): The input text to process and send to the model.\n",
    "\n",
    "    Returns:\n",
    "        dict: The response from the SageMaker endpoint.\n",
    "\n",
    "    Raises:\n",
    "        Exception: Any exception caught during processing or invoking the endpoint.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Preprocess the text using clean_text_content_trellis\n",
    "        logger.info(\"Preprocessing the input text.\")\n",
    "        processed_text = clean_text_content_trellis(text)\n",
    "\n",
    "        # Prepare the payload for SageMaker endpoint\n",
    "        payload = json.dumps({\"text\": processed_text})\n",
    "        logger.info(f\"Payload prepared: {payload}\")\n",
    "\n",
    "        # Create a runtime client\n",
    "        runtime = boto3.client('runtime.sagemaker')\n",
    "\n",
    "        # Invoke the endpoint\n",
    "        logger.info(f\"Invoking the SageMaker endpoint: {endpoint_name}\")\n",
    "        response = runtime.invoke_endpoint(\n",
    "            EndpointName=endpoint_name,\n",
    "            ContentType='application/json',\n",
    "            Body=payload\n",
    "        )\n",
    "\n",
    "        # Parse and return the response\n",
    "        response_body = response['Body'].read().decode()\n",
    "        logger.info(f\"Raw response from SageMaker endpoint: {response_body}\")\n",
    "\n",
    "        # Handle the case where the response is a list\n",
    "        if isinstance(response_body, str):\n",
    "            response_body = json.loads(response_body)\n",
    "        elif isinstance(response_body, list):\n",
    "            response_body = json.loads(response_body[0])\n",
    "\n",
    "        logger.info(f\"Parsed response from SageMaker endpoint: {response_body}\")\n",
    "        return response_body\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "#  call invoke endpoint\n",
    "if __name__ == \"__main__\":\n",
    "    endpoint_name = 'distilbert-hf-emails-trellis-document-class'  # The name of the trellis deployed endpoint\n",
    "\n",
    "    # Invoke the endpoint\n",
    "    try:\n",
    "        response = invoke_sagemaker_endpoint(endpoint_name, ent)\n",
    "        print(\"Response from SageMaker endpoint:\", response)\n",
    "        # Access the actual JSON\n",
    "        if isinstance(response, list):\n",
    "            response = json.loads(response[0])\n",
    "        predicted_class = response.get(\"predicted_class\")\n",
    "        print(\"Predicted class:\", predicted_class)\n",
    "    except Exception as e:\n",
    "        print(\"Error invoking the endpoint:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ab096d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: entertainment\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted class:\", predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f43ca9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Test latency #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b75741ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "def test_inference_time(endpoint_name, input_text):\n",
    "    \"\"\"\n",
    "    Test the inference time of the SageMaker endpoint.\n",
    "\n",
    "    Args:\n",
    "        endpoint_name (str): The name of the SageMaker endpoint.\n",
    "        input_text (str): The input text to be classified.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the response dictionary and the inference time in seconds of our Trellis Endpoint.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        response = invoke_sagemaker_endpoint(endpoint_name, input_text)\n",
    "        end_time = time.time()\n",
    "        inference_time = end_time - start_time\n",
    "        \n",
    "        # Parse the JSON from the first element of the response list\n",
    "        if isinstance(response, list):\n",
    "            response = json.loads(response[0])\n",
    "\n",
    "        return response, inference_time\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error testing inference time: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7c4d2091",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Preprocessing the input text.\n",
      "INFO:__main__:Payload prepared: {\"text\": \"Grilled Shrimp Tacos with Avocado-Corn Salsa instruction Remove the corn kernels from the cobs: Place a large container on a damp towel. Fold a paper towel into fourths and place it inside the container. Stand 1 ear of corn on the paper towel, using the stem as a handle. Using a paring knife, slice downward, letting the kernels fall into the container. Rotate the cob and continue until all the kernels have been removed; discard the cob. Repeat with the remaining corn. Discard the paper towel. Add the scallions, tomatoes, measured lime juice, cilantro, serrano, and measured salt and stir to combine. Halve and pit the avocados. Using a paring knife, score the flesh of the avocado halves in a 1/4-inch-wide crosshatch pattern (be careful not to cut through the skin). Using a spoon, scoop the avocado pieces into the corn mixture and gently fold to combine. Taste and add more lime juice or salt as needed; set aside. For the tacos: Heat an outdoor grill to high (about 450\\u00b0F to 550\\u00b0F). Meanwhile, assemble the shrimp. Whisk the lime juice, oil, chipotle powder, salt, and cumin together in a large bowl. Add the shrimp and toss to combine. Skewer each shrimp through the tail and head ends, leaving about 1/4 inch of space between each shrimp. Transfer the skewers to a baking sheet. Place the skewers in a single layer on the grill without touching. Close the grill and cook until grill marks appear on the bottom, about 4 minutes. Flip the skewers, close the grill, and cook until the shrimp are just firm, about 1 minute more. Transfer the skewers to a clean baking sheet. Remove and discard the skewers, transfer the shrimp to a cutting board, and coarsely chop. Place in a serving bowl. Serve the shrimp with the tortillas and salsa.\"}\n",
      "INFO:__main__:Invoking the SageMaker endpoint: distilbert-hf-emails-trellis-document-class\n",
      "INFO:__main__:Raw response from SageMaker endpoint: [\n",
      "  \"{\\\"predicted_class\\\": \\\"food\\\"}\",\n",
      "  \"application/json\"\n",
      "]\n",
      "INFO:__main__:Parsed response from SageMaker endpoint: ['{\"predicted_class\": \"food\"}', 'application/json']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from SageMaker endpoint: {'predicted_class': 'food'}\n",
      "Predicted class: food\n",
      "Inference time: 0.0808 seconds\n"
     ]
    }
   ],
   "source": [
    "input_news = \"\"\"\n",
    "Grilled Shrimp Tacos with Avocado-Corn Salsa\n",
    "instruction \n",
    "Remove the corn kernels from the cobs: Place a large container on a damp towel. Fold a paper towel into fourths and place it inside the container. Stand 1 ear of corn on the paper towel, using the stem as a handle. Using a paring knife, slice downward, letting the kernels fall into the container. Rotate the cob and continue until all the kernels have been removed; discard the cob. Repeat with the remaining corn. Discard the paper towel.\n",
    "Add the scallions, tomatoes, measured lime juice, cilantro, serrano, and measured salt and stir to combine.\n",
    "Halve and pit the avocados. Using a paring knife, score the flesh of the avocado halves in a 1/4-inch-wide crosshatch pattern (be careful not to cut through the skin). Using a spoon, scoop the avocado pieces into the corn mixture and gently fold to combine.\n",
    "Taste and add more lime juice or salt as needed; set aside.\n",
    "For the tacos:\n",
    "Heat an outdoor grill to high (about 450°F to 550°F). Meanwhile, assemble the shrimp.\n",
    "Whisk the lime juice, oil, chipotle powder, salt, and cumin together in a large bowl. Add the shrimp and toss to combine.\n",
    "Skewer each shrimp through the tail and head ends, leaving about 1/4 inch of space between each shrimp. Transfer the skewers to a baking sheet.\n",
    "Place the skewers in a single layer on the grill without touching. Close the grill and cook until grill marks appear on the bottom, about 4 minutes. Flip the skewers, close the grill, and cook until the shrimp are just firm, about 1 minute more. Transfer the skewers to a clean baking sheet.\n",
    "Remove and discard the skewers, transfer the shrimp to a cutting board, and coarsely chop. Place in a serving bowl.\n",
    "Serve the shrimp with the tortillas and salsa.\n",
    "\"\"\".strip()\n",
    "\n",
    "# Invoke the endpoint and test 2 inference time\n",
    "try:\n",
    "    response, inference_time = test_inference_time(endpoint_name, input_news)\n",
    "    print(\"Response from SageMaker endpoint:\", response)\n",
    "    predicted_class = response.get(\"predicted_class\")\n",
    "    print(\"Predicted class:\", predicted_class)\n",
    "    print(f\"Inference time: {inference_time:.4f} seconds\")\n",
    "except Exception as e:\n",
    "    print(\"Error invoking the endpoint:\", str(e))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7ef1ffd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Preprocessing the input text.\n",
      "INFO:__main__:Payload prepared: {\"text\": \"Talks held on Gibraltar's future Two days of talks on the future of Gibraltar begin at Jack Straw's country residence later on Wednesday. Officials at the two-day summit at the foreign secretary's official Kent house, Chevening, will plan a new forum on the Rock's future. In October, Mr Straw and his Spanish counterpart Miguel Moratinos agreed to establish a body that would give Gibraltarians a voice in their future. Most Gibraltarians said in a referendum they wanted to remain British. Gibraltar's Chief Minister Peter Caruana will represent the British citizens living on the Rock, while Britain's Europe Director Dominick Chilcott will represent the UK. Madrid is being represented by Spain's director general for Europe, Jose Maria Pons. The initiative follows Spain's socialist government's decision to put its long-standing sovereignty ambitions on hold. Gibraltarians rejected plans for the Rock's sovereignty to be shared between Britain and Spain in a referendum organised by Gibraltar government.\"}\n",
      "INFO:__main__:Invoking the SageMaker endpoint: distilbert-hf-emails-trellis-document-class\n",
      "INFO:__main__:Raw response from SageMaker endpoint: [\n",
      "  \"{\\\"predicted_class\\\": \\\"politics\\\"}\",\n",
      "  \"application/json\"\n",
      "]\n",
      "INFO:__main__:Parsed response from SageMaker endpoint: ['{\"predicted_class\": \"politics\"}', 'application/json']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from SageMaker endpoint: {'predicted_class': 'politics'}\n",
      "Predicted class: politics\n",
      "Inference time: 0.0736 seconds\n"
     ]
    }
   ],
   "source": [
    "input_news = \"\"\"\n",
    "Talks held on Gibraltar's future\n",
    "\n",
    "Two days of talks on the future of Gibraltar begin at Jack Straw's country residence later on Wednesday.\n",
    "\n",
    "Officials at the two-day summit at the foreign secretary's official Kent house, Chevening, will plan a new forum on the Rock's future. In October, Mr Straw and his Spanish counterpart Miguel Moratinos agreed to establish a body that would give Gibraltarians a voice in their future. Most Gibraltarians said in a referendum they wanted to remain British.\n",
    "\n",
    "Gibraltar's Chief Minister Peter Caruana will represent the British citizens living on the Rock, while Britain's Europe Director Dominick Chilcott will represent the UK. Madrid is being represented by Spain's director general for Europe, Jose Maria Pons. The initiative follows Spain's socialist government's decision to put its long-standing sovereignty ambitions on hold. Gibraltarians rejected plans for the Rock's sovereignty to be shared between Britain and Spain in a referendum organised by Gibraltar government.\n",
    "\n",
    "\"\"\".strip()\n",
    "\n",
    "# Invoke the endpoint and test 2 inference time\n",
    "try:\n",
    "    response, inference_time = test_inference_time(endpoint_name, input_news)\n",
    "    print(\"Response from SageMaker endpoint:\", response)\n",
    "    predicted_class = response.get(\"predicted_class\")\n",
    "    print(\"Predicted class:\", predicted_class)\n",
    "    print(f\"Inference time: {inference_time:.4f} seconds\")\n",
    "except Exception as e:\n",
    "    print(\"Error invoking the endpoint:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0d3058",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
